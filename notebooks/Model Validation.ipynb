{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cb402d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb229b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_face_detection = mp.solutions.face_detection\n",
    "\n",
    "face_detector = mp_face_detection.FaceDetection(\n",
    "    min_detection_confidence=0.6\n",
    ")\n",
    "valid_split_path = '../validation/raw'\n",
    "valid_cropped_split_path = '../validation/cropped'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dea3680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, 48, 48, 64)        640       \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 48, 48, 64)        36928     \n",
      "                                                                 \n",
      " block1_maxpool (MaxPooling2  (None, 24, 24, 64)       0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 24, 24, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 24, 24, 128)       147584    \n",
      "                                                                 \n",
      " block2_maxpool (MaxPooling2  (None, 12, 12, 128)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 12, 12, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " block3_maxpool (MaxPooling2  (None, 6, 6, 256)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 6, 6, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block4_maxpool (MaxPooling2  (None, 3, 3, 512)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " block5_maxpool (MaxPooling2  (None, 1, 1, 512)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              2101248   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 32776     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,628,872\n",
      "Trainable params: 33,628,872\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3,3), activation='relu', padding='same', kernel_regularizer=l2(1e-7), kernel_initializer='he_uniform', name='block1_conv1', input_shape=(48, 48, 1) ))\n",
    "model.add(Conv2D(64, (3,3), activation='relu', padding='same', kernel_regularizer=l2(1e-7), kernel_initializer='he_uniform', name='block1_conv2'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), name='block1_maxpool'))\n",
    "\n",
    "model.add(Conv2D(128, (3,3), activation='relu', padding='same', kernel_regularizer=l2(1e-7), kernel_initializer='he_uniform', name='block2_conv1'))\n",
    "model.add(Conv2D(128, (3,3), activation='relu', padding='same', kernel_regularizer=l2(1e-7), kernel_initializer='he_uniform', name='block2_conv2'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), name='block2_maxpool'))\n",
    "\n",
    "model.add(Conv2D(256, (3,3), activation='relu', padding='same', kernel_regularizer=l2(1e-7), kernel_initializer='he_uniform', name='block3_conv1'))\n",
    "model.add(Conv2D(256, (3,3), activation='relu', padding='same', kernel_regularizer=l2(1e-7), kernel_initializer='he_uniform', name='block3_conv2'))\n",
    "model.add(Conv2D(256, (3,3), activation='relu', padding='same', kernel_regularizer=l2(1e-7), kernel_initializer='he_uniform', name='block3_conv3'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), name='block3_maxpool'))\n",
    "\n",
    "model.add(Conv2D(512, (3,3), activation='relu', padding='same', kernel_regularizer=l2(1e-7), kernel_initializer='he_uniform', name='block4_conv1'))\n",
    "model.add(Conv2D(512, (3,3), activation='relu', padding='same', kernel_regularizer=l2(1e-7), kernel_initializer='he_uniform', name='block4_conv2'))\n",
    "model.add(Conv2D(512, (3,3), activation='relu', padding='same', kernel_regularizer=l2(1e-7), kernel_initializer='he_uniform', name='block4_conv3'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), name='block4_maxpool'))\n",
    "\n",
    "model.add(Conv2D(512, (3,3), activation='relu', padding='same', kernel_regularizer=l2(1e-7), kernel_initializer='he_uniform', name='block5_conv1'))\n",
    "model.add(Conv2D(512, (3,3), activation='relu', padding='same', kernel_regularizer=l2(1e-7), kernel_initializer='he_uniform', name='block5_conv2'))\n",
    "model.add(Conv2D(512, (3,3), activation='relu', padding='same', kernel_regularizer=l2(1e-7), kernel_initializer='he_uniform', name='block5_conv3'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), name='block5_maxpool'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, kernel_regularizer=l2(1e-7), activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(4096, kernel_regularizer=l2(1e-7), activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0002), loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00302742",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('../models/VGG16-best_loss_model.h5')\n",
    "class_labels = {0: 'angry', 1: 'contempt', 2: 'disgust', 3: 'fear', 4: 'happy', 5: 'neutral', 6: 'sad', 7: 'surprise'}\n",
    "label_classes = {'angry': 0, 'contempt': 1, 'disgust': 2, 'fear': 3, 'happy': 4, 'neutral': 5, 'sad': 6, 'surprise': 7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6821938c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "347"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_dirs = os.listdir(valid_split_path)\n",
    "corrupted = 0\n",
    "\n",
    "for sd in sub_dirs:\n",
    "    sd_path = os.path.join(valid_split_path, sd)\n",
    "    img_files = os.listdir(sd_path)\n",
    "\n",
    "    for i, f in enumerate(img_files):\n",
    "        img_file_path = os.path.join(sd_path, f)\n",
    "\n",
    "        try:\n",
    "            img = cv2.imread(img_file_path)\n",
    "            h, w, _ = img.shape\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            face_detect_results = face_detector.process(img_rgb)\n",
    "            img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
    "            \n",
    "            if face_detect_results.detections:\n",
    "                for face in face_detect_results.detections:\n",
    "                    rel_bound_rect = face.location_data.relative_bounding_box\n",
    "                    face_x, face_w, face_y, face_h = int(rel_bound_rect.xmin * w), int(rel_bound_rect.width * w), int(rel_bound_rect.ymin * h), int(rel_bound_rect.height * h)\n",
    "                    cropped_face = img_gray[face_y: face_y + face_h, face_x: face_x + face_w]\n",
    "                    processed_img = cv2.resize(cropped_face, (48, 48))\n",
    "                    rescaled = processed_img / 255.0\n",
    "                    reshaped = np.reshape(rescaled, (1, rescaled.shape[0], rescaled.shape[1], 1))\n",
    "                    preds = model.predict(reshaped)\n",
    "                    pred = np.argmax(preds, axis=1)[0]\n",
    "                    label = class_labels[pred]\n",
    "                    \n",
    "                    angry_acc = round(preds[0][0] * 100, 1)\n",
    "                    contempt_acc = round(preds[0][1] * 100, 1)\n",
    "                    disgust_acc = round(preds[0][2] * 100, 1)\n",
    "                    fear_acc = round(preds[0][3] * 100, 1)\n",
    "                    happy_acc = round(preds[0][4] * 100, 1)\n",
    "                    neutral_acc = round(preds[0][5] * 100, 1)\n",
    "                    sad_acc = round(preds[0][6] * 100, 1)\n",
    "                    surprise_acc = round(preds[0][7] * 100, 1)\n",
    "                    pred_acc = round(preds[0][pred] * 100, 1)\n",
    "                    \n",
    "                    pred_summary = f\"angry: {angry_acc}\\ncontempt: {contempt_acc}\\ndisgust: {disgust_acc}\\nfear: {fear_acc}\\nhappy: {happy_acc}\\nneutral: {neutral_acc}\\nsad: {sad_acc}\\nsurprise: {surprise_acc}\\n\"\n",
    "                    pred_summary_path = os.path.join(os.path.join(valid_cropped_split_path, sd))\n",
    "                    pred_summary_path += f'\\img_{i}'\n",
    "                    pred_summary_file = open(f'{pred_summary_path}.txt', 'w')\n",
    "                    \n",
    "                    cv2.rectangle(img, (face_x, face_y), (face_x + face_w, face_y + face_h), (0, 255, 0), 1)\n",
    "                    cv2.putText(img, f'{label}: {pred_acc}%', (face_x, face_y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.55, (0, 255, 0), 1)\n",
    "                    \n",
    "                    cv2.imwrite(os.path.join(f'{pred_summary_path}.jpg'), img)\n",
    "                    pred_summary_file.write(pred_summary)\n",
    "                    pred_summary.close()\n",
    "        except:\n",
    "            corrupted += 1\n",
    "\n",
    "corrupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de847359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(339, 48, 48, 1) (339, 8)\n"
     ]
    }
   ],
   "source": [
    "valid_X = []\n",
    "valid_y = []\n",
    "sub_dirs = os.listdir(valid_split_path)\n",
    "corrupted = 0\n",
    "\n",
    "for sd in sub_dirs:\n",
    "    sd_path = os.path.join(valid_split_path, sd)\n",
    "    img_files = os.listdir(sd_path)\n",
    "\n",
    "    for i, f in enumerate(img_files):\n",
    "        img_file_path = os.path.join(sd_path, f)\n",
    "\n",
    "        try:\n",
    "            img = cv2.imread(img_file_path)\n",
    "            h, w, _ = img.shape\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            face_detect_results = face_detector.process(img_rgb)\n",
    "            img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
    "            \n",
    "            if face_detect_results.detections:\n",
    "                for face in face_detect_results.detections:\n",
    "                    rel_bound_rect = face.location_data.relative_bounding_box\n",
    "                    face_x, face_w, face_y, face_h = int(rel_bound_rect.xmin * w), int(rel_bound_rect.width * w), int(rel_bound_rect.ymin * h), int(rel_bound_rect.height * h)\n",
    "                    cropped_face = img_gray[face_y: face_y + face_h, face_x: face_x + face_w]\n",
    "                    processed_img = cv2.resize(cropped_face, (48, 48))\n",
    "                    valid_X.append(processed_img)\n",
    "                    valid_y.append(label_classes[sd])\n",
    "        except:\n",
    "            corrupted += 1\n",
    "\n",
    "valid_X = np.array(valid_X)\n",
    "valid_y = np.array(valid_y)\n",
    "valid_X = valid_X / 255.0\n",
    "valid_X = np.reshape(valid_X, (valid_X.shape[0], valid_X.shape[1], valid_X.shape[2], 1))\n",
    "valid_y = np_utils.to_categorical(valid_y)\n",
    "\n",
    "print(valid_X.shape, valid_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "218bce57",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('../models/VGG16-best_loss_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca13e05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 6s 550ms/step - loss: 4.1993 - accuracy: 0.5251\n",
      "4.19926118850708 0.525073766708374\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(valid_X, valid_y)\n",
    "\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc9a66aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('../models/VGG16-best_val_loss_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12e7379d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 5s 465ms/step - loss: 3.1193 - accuracy: 0.5162\n",
      "3.11932110786438 0.516224205493927\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(valid_X, valid_y)\n",
    "\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c980bcd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "b2b9ed2f758ea7019c62ddc2c4686da189c449cf25e556e37851562caab2f41e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
